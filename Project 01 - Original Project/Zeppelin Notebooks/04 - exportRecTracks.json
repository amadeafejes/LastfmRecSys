{"paragraphs":[{"text":"//read tracks file\nval rawListenings = sc.textFile(\"hdfs://127.0.0.1/user/cloudera/lastfm_output/listenings.tsv\")\n\n//count unique user-track occurences\ncase class SimpleListening(userid:String, traid:String, timestamp:String)\nval rawTracks = rawListenings.map(_.split(\"\\t\")).map(s => SimpleListening(s(1), s(0), s(2)))\nval userTrackPairs = rawTracks.map( r => (r.userid, r.traid) )\nval countedTrackMap = userTrackPairs.map(s => (s,1))\nval countedTracks = countedTrackMap.reduceByKey(_ + _)\nval ratingData = countedTracks.map(s => (s._1._1, s._1._2, s._2))\n\n//import ALS and Rating from MLlib\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.Rating\n\n//create rating object from tuple with hash values of id-s\nval ratings = ratingData.map(t => Rating(t._1.toInt, t._2.toInt, t._3.toDouble))\n//split data into training and test set\nval splits = ratings.randomSplit(Array(0.8, 0.2))\nval trainRatings = splits(0)\nval testRatings = splits(1)\n\n//import RDD\nimport org.apache.spark.rdd.RDD\n//method to create model and count rmse for a given Rating rdd\ndef countRMSE( ratings:RDD[Rating], rank:Int, iterations:Int, lambda:Double, alpha:Double) : Double = {\n    \n//create a model\nval model = ALS.trainImplicit(ratings, rank, iterations, lambda, alpha)\n    \n val usersProducts = ratings.map { case Rating(user, product, rate) =>\n  (user, product)\n}\nval predictions =\n  model.predict(usersProducts).map { case Rating(user, product, rate) =>\n    ((user, product), rate)\n  }\nval ratesAndPreds = ratings.map { case Rating(user, product, rate) =>\n  ((user, product), rate)\n}.join(predictions)\nval MSE = ratesAndPreds.map { case ((user, product), (r1, r2)) =>\n  val err = (r1 - r2)\n  err * err\n}.mean()\n\nval RMSE = math.sqrt(MSE)\n\nreturn RMSE\n\n}\n\n//default parameters for the function\nval rank = 50\nval iterations = 10\nval lambda = 0.01\nval alpha = 1.0\n","dateUpdated":"May 23, 2016 12:02:26 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461684166307_2023025037","id":"20160426-082246_432346750","result":{"code":"SUCCESS","type":"TEXT","msg":"rawListenings: org.apache.spark.rdd.RDD[String] = hdfs://127.0.0.1/user/cloudera/lastfm_output/listenings.tsv MapPartitionsRDD[1] at textFile at <console>:24\ndefined class SimpleListening\nrawTracks: org.apache.spark.rdd.RDD[SimpleListening] = MapPartitionsRDD[3] at map at <console>:27\nuserTrackPairs: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[4] at map at <console>:29\ncountedTrackMap: org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[5] at map at <console>:31\ncountedTracks: org.apache.spark.rdd.RDD[((String, String), Int)] = ShuffledRDD[6] at reduceByKey at <console>:33\nratingData: org.apache.spark.rdd.RDD[(String, String, Int)] = MapPartitionsRDD[7] at map at <console>:35\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.Rating\nratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[8] at map at <console>:41\nsplits: Array[org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating]] = Array(PartitionwiseSampledRDD[9] at randomSplit at <console>:42, PartitionwiseSampledRDD[10] at randomSplit at <console>:42)\ntrainRatings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = PartitionwiseSampledRDD[9] at randomSplit at <console>:42\ntestRatings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = PartitionwiseSampledRDD[10] at randomSplit at <console>:42\nimport org.apache.spark.rdd.RDD\ncountRMSE: (ratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating], rank: Int, iterations: Int, lambda: Double, alpha: Double)Double\nrank: Int = 10\niterations: Int = 5\nlambda: Double = 0.01\nalpha: Double = 1.0\n"},"dateCreated":"Apr 26, 2016 8:22:46 AM","dateStarted":"May 23, 2016 11:35:35 AM","dateFinished":"May 23, 2016 11:35:53 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:771","focus":true},{"text":"//function for counting more error and rmse between the given parameter ranges\ndef countRMSEErrorInBlock(rankMin:Double, rankMax:Double, iterationsMin:Double, iterationsMax:Double, lambdaMin:Double, lambdaMax:Double, alphaMin:Double, alphaMax:Double){\n    \n    val rankStep = 20\n    val iterationsStep = 2\n    val lambdaStep = 0.002\n    val alphaStep = 0.1\n     \n    for (r <- rankMin to rankMax by rankStep){\n        for (i <- iterationsMin to iterationsMax by iterationsStep){\n            for (l <- lambdaMin to lambdaMax by lambdaStep){\n                for (a <- alphaMin to alphaMax by alphaStep){\n                    //call rmse method\n                    val rmse = countRMSE(ratings, r.toInt, i.toInt, l, a)\n                    val rmseTrain = countRMSE(trainRatings, r.toInt, i.toInt, l, a)\n                    val rmseTest = countRMSE(testRatings, r.toInt, i.toInt, l, a)\n                    val error = math.abs(rmseTrain - rmseTest)\n                    \n                    val resultString = error + \"\\t\" + rmse + \"\\t\" + r + \"\\t\" + i + \"\\t\" + l + \"\\t\" + a\n                    \n                    println(resultString)\n                }\n            }\n        }\n    }\n}\n\n\n","dateUpdated":"May 23, 2016 12:01:24 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461684166307_2023025037","id":"20160426-082246_442137805","result":{"code":"SUCCESS","type":"TEXT","msg":"countRMSEErrorInBlock: (rankMin: Double, rankMax: Double, iterationsMin: Double, iterationsMax: Double, lambdaMin: Double, lambdaMax: Double, alphaMin: Double, alphaMax: Double)Unit\n"},"dateCreated":"Apr 26, 2016 8:22:46 AM","dateStarted":"May 23, 2016 11:37:52 AM","dateFinished":"May 23, 2016 11:37:53 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:773","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1464030065228_-1721463865","id":"20160523-120105_1623330742","dateCreated":"May 23, 2016 12:01:05 PM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:925","text":"//example calls of the above function\n//only rank changes\ncountRMSEErrorInBlock(10, 120, iterations, iterations, lambda, lambda, alpha, alpha)\n//only iterations changes\ncountRMSEErrorInBlock(rank, rank, 6, 17, lambda, lambda, alpha, alpha)\n//only lambda changes\ncountRMSEErrorInBlock(rank, rank, iterations, iterations, 0.002, 0.024, alpha, alpha)\n//only alpha changes\ncountRMSEErrorInBlock(rank, rank, iterations, iterations, lambda, lambda, 0.4, 1.5)","dateUpdated":"May 23, 2016 12:05:09 PM"},{"text":"////generate top k recommendations for all users and save the results into files\n\n\nval model = ALS.trainImplicit(ratings, rank, iterations, lambda, alpha)\n\nval ratingValues = model.userFeatures.map( r => r._2 ).flatMap( r => r)\nval maxValue = ratingValues.max()\nval avgValue = ratingValues.sum/ratingValues.count\nval percentageUpper = (maxValue - avgValue)/50\nval percentageLower = avgValue/50\n\nval userIDs = ratingData.map(t => t._1.toInt ).distinct()\nuserIDs.count\nuserIDs.take(5)\nval K=10\nval folder = \"hdfs://127.0.0.1/user/cloudera/lastfm_output/rec_tracks/\"\nval fileExt = \".tsv\"\n\nval recs =  userIDs.collect().foreach(\n      \n      userID => sc.parallelize( model.recommendProducts(userID, K).map(r => (r.user + \"\\t\" + r.product + \"\\t\" + \n      (\n      //count percentage value from rating\n      if(r.rating >= avgValue) (50 + (r.rating/percentageUpper))\n      else (50 - (r.rating/percentageLower))\n      )\n       ) ) ).saveAsTextFile(folder + userID + fileExt)\n    \n)","dateUpdated":"May 23, 2016 12:01:52 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1463939090152_1751182362","id":"20160522-104450_1515158565","result":{"code":"SUCCESS","type":"TEXT","msg":"rank: Int = 10\niterations: Int = 5\nlambda: Double = 0.01\nalpha: Double = 1.0\nmodel: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@42c8948f\nratingValues: org.apache.spark.rdd.RDD[Double] = MapPartitionsRDD[406] at flatMap at <console>:55\nmaxValue: Double = 1.8915400505065918\navgValue: Double = 0.04677919744523831\npercentageUpper: Double = 0.03689521706122707\npercentageLower: Double = 9.355839489047662E-4\nuserIDs: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[410] at distinct at <console>:43\nres49: Long = 992\nres50: Array[Int] = Array(817, 570, 19, 475, 893)\nK: Int = 10\nfolder: String = hdfs://127.0.0.1/user/cloudera/lastfm_output/rec_tracks/\nfileExt: String = .tsv\nrecs: Unit = ()\n"},"dateCreated":"May 22, 2016 10:44:50 AM","dateStarted":"May 22, 2016 11:13:39 AM","dateFinished":"May 22, 2016 11:42:44 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:776"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1463939654361_-1676732768","id":"20160522-105414_1105718187","dateCreated":"May 22, 2016 10:54:14 AM","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:777"}],"name":"04 - exportRecTracks","id":"2BH4A3N6C","angularObjects":{"2BJEX9EKE":[],"2BHNRNXUS":[],"2BHYW4VGK":[],"2BKF83PSM":[],"2BM15S4NY":[],"2BKATJKHF":[],"2BJBC6G63":[],"2BJP5SDEU":[],"2BJAXCR48":[],"2BM76CV5M":[],"2BGC3HU85":[],"2BH7HBVDY":[],"2BJ46877K":[],"2BGV7SN9S":[]},"config":{"looknfeel":"default"},"info":{}}